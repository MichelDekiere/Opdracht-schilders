{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht schilderijen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from keras import layers\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_with_labels(dataset_dir):\n",
    "    \"\"\"\n",
    "    Labelt de data (0 = Mondriaan, 1 = Picasso, 2 = Rubens, ...)\n",
    "    Print welke files corrupted zijn. (bv. data\\Picasso\\\\150.jpg --> FAILED)\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "            subdirectories to different classes.\n",
    "    Returns:\n",
    "        de data met de labels\n",
    "    \"\"\"\n",
    "    image_paths_per_label = collect_paths_to_files(dataset_dir)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, image_paths in image_paths_per_label.items():\n",
    "        for image_path in image_paths:\n",
    "\n",
    "            # print(str(image_path))\n",
    "\n",
    "            img = cv2.imread(str(image_path))\n",
    "\n",
    "            if(img is not None):\n",
    "                # print(f\"{i} {str(image_path)} --> succes\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                images.append(img)\n",
    "                \n",
    "                # print(label)\n",
    "                labels.append(label)       \n",
    "                      \n",
    "            else:\n",
    "                print(f\"{str(image_path)} --> FAILED\")\n",
    "                \n",
    "    data = np.array([preprocess_image(image.astype(np.float32))\n",
    "                for image in images])\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "        \n",
    "    return data, labels\n",
    "\n",
    "def collect_paths_to_files(dataset_dir):\n",
    "    \"\"\"Returns a dict with labels for each subdirectory of the given directory\n",
    "    as keys and lists of the subdirectory's contents as values.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "            subdirectories to different classes.\n",
    "    Returns:\n",
    "        image_paths_per_label: A dict with labels as keys and lists of file\n",
    "        paths as values.\n",
    "    \"\"\"\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    painter_dirs = [f for f in sorted(os.listdir(dataset_dir)) if not f.startswith('.')]\n",
    "    image_paths_per_label = {\n",
    "        label: [\n",
    "            dataset_dir / painter_dir / '{0}'.format(f)\n",
    "            for f in os.listdir(dataset_dir / painter_dir) if not f.startswith('.')\n",
    "        ]\n",
    "        for label, painter_dir in enumerate(painter_dirs)\n",
    "    }\n",
    "    return image_paths_per_label\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Returns a preprocessed image.\n",
    "\n",
    "    Parameters:\n",
    "        image: A RGB image with pixel values in range [0, 255].\n",
    "    Returns\n",
    "        image: The preprocessed image.\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.resize(image, (180, 180))\n",
    "    image = image / 255.\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels) = create_data_with_labels(\"dataset/train/\")\n",
    "(val_data, val_labels) = create_data_with_labels(\"dataset/validation\")\n",
    "(test_data, test_labels) = create_data_with_labels(\"dataset/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model opbouwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.Input(shape=(180, 180, 3)) \n",
    "\n",
    "x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(input_layer)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)  # 4 because we have 4 classes (0 through 3)\n",
    "\n",
    "model = keras.Model(inputs=input_layer, outputs=outputs)\n",
    "\n",
    "# Return the compiled model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "  # categorical crossentropy because we're dealing with multiclass, single label classification\n",
    "  optimizer=keras.optimizers.RMSprop(),\n",
    "  metrics=[\"accuracy\"],  # =0.00001\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"convnet_from_scratch.keras\",  # file waarin model wordt opgeslagen\n",
    "    save_best_only=True,  # beste model wordt opgeslagen obv validation loss!\n",
    "    monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=30,\n",
    "    validation_data=(val_data, val_labels),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "fig.set_size_inches(12, 3)\n",
    "\n",
    "ax1.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "ax1.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "ax1.set_title(\"Training and validation accuracy\")\n",
    "ax1.legend()\n",
    "# plt.figure()\n",
    "\n",
    "ax2.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "ax2.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "ax2.set_title(\"Training and validation loss\")\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5b5e7454dee2b7ac0a78092e9f6ca3b873477174af0fb8ff811e8dbf4700344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
