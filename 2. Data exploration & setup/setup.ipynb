{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht schilderijen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, shutil, pathlib\n",
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opzetten omgeving\n",
    "\n",
    "Ik heb gewerkt met mijn lokale GPU. Op dit op te zetten maakte ik gebruik van deze [bron](https://towardsdatascience.com/the-ultimate-tensorflow-gpu-installation-guide-for-2022-and-beyond-27a88f5e6c6e). Ik downloadde de CUDA toolkit en CuDNN, maar maakte geen gebruik van anaconda. Ik heb dit zowel op mijn laptop als op mijn desktop proberen op te zetten. Op mijn laptop is dit zonder enige problemen gelukt, om mijn desktop is dit uiteindelijk niet gelukt.\n",
    "\n",
    "Ik maakte gebruik van de ingebouwde NVIDIA Geforce RTX 2060 in mijn laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check hoeveel images per schilder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_amount_of_images(dir_path):\n",
    "    count = 0\n",
    "    for path in os.listdir(dir_path):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path, path)):\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "for painter in os.listdir(\"data\"):\n",
    "    print(f'File count {painter}: {check_amount_of_images(f\"data/{painter}\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dat de data zeer ongebalanceerd is, we kunnen dit oplossen door het willekeurig kopiëren van samples in de klassen met te weinig samples (oversampled methode).\n",
    "De dubbels zullen dan worden weggewerkt met data augmentation technieken.\n",
    "\n",
    "We kunnen ook schilderijen van Picasso achterwege laten tot we enzelfde aantal schilderijen hebben in iedere klasse (undersampled methode), maar dit lijkt me jammer dat we deze schilderijen hebben maar toch niet zouden gebruiken voor het model.\n",
    "We kunnen experimenteren met beide, maar ik zal beginnen met de oversampled methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dir_path):\n",
    "    \"\"\"\n",
    "    Random images kopiëren tot dat alle klassen hetzelfde aantal images hebben en dus gebalanceerd zijn.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "        subdirectories to different classes.\n",
    "    \"\"\"\n",
    "\n",
    "    sizes = [check_amount_of_images(f\"{dir_path}/{painter}\") for painter in os.listdir(dir_path)]\n",
    "    target_size = max(sizes)\n",
    "    biggest_class = os.listdir(dir_path)[sizes.index(target_size)]\n",
    "\n",
    "    for cls in os.listdir(dir_path):\n",
    "        if (cls != biggest_class):\n",
    "            \n",
    "            while check_amount_of_images(f\"{dir_path}/{cls}\") < target_size:\n",
    "\n",
    "                random_file = random.choice(os.listdir(f\"{dir_path}/{cls}\"))\n",
    "                shutil.copy(f\"{dir_path}/{cls}/{random_file}\", f\"{dir_path}/{cls}/{random.randint(0,1000)}.{random_file}\") # random int voor naam zetten anders zou \n",
    "                # de image gewoon overgeschreven worden en zou het aantal niet omhoog gaan\n",
    "                # indien de random_int al bestaat wordt deze gewoon overgeschreven, dus geen nood aan error catch\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_dataset(\"data\")\n",
    "\n",
    "for painter in os.listdir(\"data\"):\n",
    "    print(f'File count {painter}: {check_amount_of_images(f\"data/{painter}\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iedere klasse heeft nu hetzelfde aantal images, de dataset is nu wel gebalanceerd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(dir_path):\n",
    "    \"\"\"\"\n",
    "    Hernoemen van de files naar de nummering per schilder, dit formaat is nodig voor het goed functioneren van een latere functie (make_subset)\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "            subdirectories to different classes.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "\n",
    "    for path in os.listdir(dir_path):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path, path)):\n",
    "            os.rename(f\"{dir_path}/{path}\", f\"{dir_path}/{i}.jpg\")\n",
    "            i += 1\n",
    "\n",
    "        \n",
    "# data cleanup functies toepassen om iedere directory\n",
    "for painter in os.listdir(\"data\"):\n",
    "    # remove_duplicates(f\"data/{painter}\")\n",
    "    rename_files(f\"data/{painter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opsplitsen van de data in train-, validatie en testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = pathlib.Path(\"data\")\n",
    "new_base_dir = pathlib.Path(\"dataset\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in os.listdir(\"data\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / category / fname,\n",
    "            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=918) # 60% trainingsset\n",
    "make_subset(\"validation\", start_index=918, end_index=1223) # 20% validatieset\n",
    "make_subset(\"test\", start_index=1223, end_index=1529) # 20% testset\n",
    "\n",
    "# make_subset(\"train\", start_index=0, end_index=400) # 60% trainingsset\n",
    "# make_subset(\"validation\", start_index=400, end_index=500) # 20% validatieset\n",
    "# make_subset(\"test\", start_index=500, end_index=600) # 20% testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inlezen, preprocessen & labelen van de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_with_labels(dataset_dir):\n",
    "    \"\"\"\n",
    "    Labelt de data (0 = Mondriaan, 1 = Picasso, 2 = Rubens, ...)\n",
    "    Print welke files corrupted zijn. (bv. data\\Picasso\\\\145.jpg --> FAILED)\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "            subdirectories to different classes.\n",
    "    Returns:\n",
    "        de data met de labels\n",
    "    \"\"\"\n",
    "    image_paths_per_label = collect_paths_to_files(dataset_dir)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, image_paths in image_paths_per_label.items():\n",
    "        for image_path in image_paths:\n",
    "\n",
    "            # print(str(image_path))\n",
    "\n",
    "            img = cv2.imread(str(image_path))\n",
    "\n",
    "            if(img is not None):\n",
    "                # print(f\"{i} {str(image_path)} --> succes\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                images.append(img)\n",
    "                \n",
    "                # print(label)\n",
    "                labels.append(label)       \n",
    "                      \n",
    "            else:\n",
    "                print(f\"{str(image_path)} --> FAILED\")\n",
    "                \n",
    "    data = np.array([preprocess_image(image.astype(np.float32))\n",
    "                for image in images])\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "        \n",
    "    return data, labels\n",
    "\n",
    "def collect_paths_to_files(dataset_dir):\n",
    "    \"\"\"Returns a dict with labels for each subdirectory of the given directory\n",
    "    as keys and lists of the subdirectory's contents as values.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "            subdirectories to different classes.\n",
    "    Returns:\n",
    "        image_paths_per_label: A dict with labels as keys and lists of file\n",
    "        paths as values.\n",
    "    \"\"\"\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    painter_dirs = [f for f in sorted(os.listdir(dataset_dir)) if not f.startswith('.')]\n",
    "    image_paths_per_label = {\n",
    "        label: [\n",
    "            dataset_dir / painter_dir / '{0}'.format(f)\n",
    "            for f in os.listdir(dataset_dir / painter_dir) if not f.startswith('.')\n",
    "        ]\n",
    "        for label, painter_dir in enumerate(painter_dirs)\n",
    "    }\n",
    "    return image_paths_per_label\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Returns a preprocessed image.\n",
    "\n",
    "    Parameters:\n",
    "        image: A RGB image with pixel values in range [0, 255].\n",
    "    Returns\n",
    "        image: The preprocessed image.\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.resize(image, (180, 180))\n",
    "    image = image / 255.\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels) = create_data_with_labels(\"dataset/train/\")\n",
    "(val_data, val_labels) = create_data_with_labels(\"dataset/validation\")\n",
    "(test_data, test_labels) = create_data_with_labels(\"dataset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ter controle, we zien dat de het resizen naar 180x180 gelukt is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60a9a335d522aefda6eaa043709c97f9746d66f97309f2f09eaf1fc365ea87e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
