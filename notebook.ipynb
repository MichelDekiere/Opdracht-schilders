{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht schilderijen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, shutil, pathlib\n",
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check hoeveel images per schilder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File count Mondriaan: 330\n",
      "File count Picasso: 1529\n",
      "File count Rubens: 682\n"
     ]
    }
   ],
   "source": [
    "def check_amount_of_images(dir_path):\n",
    "    count = 0\n",
    "    for path in os.listdir(dir_path):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path, path)):\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "for painter in os.listdir(\"data\"):\n",
    "    print(f'File count {painter}: {check_amount_of_images(f\"data/{painter}\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dat de data zeer ongebalanceerd is, we kunnen dit oplossen door het willekeurig kopiëren van samples in de klassen met te weinig samples (undersampled klassen).\n",
    "De dubbels zullen dan worden weggewerkt met data augmentation technieken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dir_path):\n",
    "    \"\"\"\n",
    "    Random images kopiëren tot dat alle klassen hetzelfde aantal images hebben en dus gebalanceerd zijn.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "        subdirectories to different classes.\n",
    "    \"\"\"\n",
    "\n",
    "    sizes = [check_amount_of_images(f\"{dir_path}/{painter}\") for painter in os.listdir(dir_path)]\n",
    "    target_size = max(sizes)\n",
    "    biggest_class = os.listdir(dir_path)[sizes.index(target_size)]\n",
    "\n",
    "    for cls in os.listdir(dir_path):\n",
    "        if (cls != biggest_class):\n",
    "            \n",
    "            while check_amount_of_images(f\"{dir_path}/{cls}\") < target_size:\n",
    "\n",
    "                random_file = random.choice(os.listdir(f\"{dir_path}/{cls}\"))\n",
    "                shutil.copy(f\"{dir_path}/{cls}/{random_file}\", f\"{dir_path}/{cls}/{random.randint(0,1000)}.{random_file}\") # random int voor naam zetten anders zou \n",
    "                # de image gewoon overgeschreven worden en zou het aantal niet omhoog gaan\n",
    "                # indien de random_int al bestaat wordt deze gewoon overgeschreven, dus geen nood aan error catch\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File count Mondriaan: 1529\n",
      "File count Picasso: 1529\n",
      "File count Rubens: 1529\n"
     ]
    }
   ],
   "source": [
    "balance_dataset(\"data\")\n",
    "\n",
    "for painter in os.listdir(\"data\"):\n",
    "    print(f'File count {painter}: {check_amount_of_images(f\"data/{painter}\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iedere klasse heeft nu hetzelfde aantal images, de dataset is nu wel gebalanceerd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(dir_path):\n",
    "    \"\"\"\"\n",
    "    Hernoemen van de files naar de nummering per schilder, dit formaat is nodig voor het goed functioneren van een latere functie (make_subset)\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "            subdirectories to different classes.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "\n",
    "    for path in os.listdir(dir_path):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path, path)):\n",
    "            os.rename(f\"{dir_path}/{path}\", f\"{dir_path}/{i}.jpg\")\n",
    "            i += 1\n",
    "\n",
    "        \n",
    "# data cleanup functies toepassen om iedere directory\n",
    "for painter in os.listdir(\"data\"):\n",
    "    # remove_duplicates(f\"data/{painter}\")\n",
    "    rename_files(f\"data/{painter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opsplitsen van de data in train-, validatie en testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = pathlib.Path(\"data\")\n",
    "new_base_dir = pathlib.Path(\"dataset\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in os.listdir(\"data\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / category / fname,\n",
    "            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=918) # 60% trainingsset\n",
    "make_subset(\"validation\", start_index=918, end_index=1223) # 20% validatieset\n",
    "make_subset(\"test\", start_index=1223, end_index=1529) # 20% testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inlezen, preprocessen & labelen van de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_with_labels(dataset_dir):\n",
    "    \"\"\"\n",
    "    Labelt de data (0 = Mondriaan, 1 = Picasso, 2 = Rubens, ...)\n",
    "    Print welke files corrupted zijn. (bv. data\\Picasso\\\\145.jpg --> FAILED)\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "            subdirectories to different classes.\n",
    "    Returns:\n",
    "        de data met de labels\n",
    "    \"\"\"\n",
    "    image_paths_per_label = collect_paths_to_files(dataset_dir)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, image_paths in image_paths_per_label.items():\n",
    "        for image_path in image_paths:\n",
    "\n",
    "            # print(str(image_path))\n",
    "\n",
    "            img = cv2.imread(str(image_path))\n",
    "\n",
    "            if(img is not None):\n",
    "                # print(f\"{i} {str(image_path)} --> succes\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                images.append(img)\n",
    "                \n",
    "                # print(label)\n",
    "                labels.append(label)       \n",
    "                      \n",
    "            else:\n",
    "                print(f\"{str(image_path)} --> FAILED\")\n",
    "                \n",
    "    data = np.array([preprocess_image(image.astype(np.float32))\n",
    "                for image in images])\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "        \n",
    "    return data, labels\n",
    "\n",
    "def collect_paths_to_files(dataset_dir):\n",
    "    \"\"\"Returns a dict with labels for each subdirectory of the given directory\n",
    "    as keys and lists of the subdirectory's contents as values.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dir: A string containing the path to a directory containing\n",
    "            subdirectories to different classes.\n",
    "    Returns:\n",
    "        image_paths_per_label: A dict with labels as keys and lists of file\n",
    "        paths as values.\n",
    "    \"\"\"\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    painter_dirs = [f for f in sorted(os.listdir(dataset_dir)) if not f.startswith('.')]\n",
    "    image_paths_per_label = {\n",
    "        label: [\n",
    "            dataset_dir / painter_dir / '{0}'.format(f)\n",
    "            for f in os.listdir(dataset_dir / painter_dir) if not f.startswith('.')\n",
    "        ]\n",
    "        for label, painter_dir in enumerate(painter_dirs)\n",
    "    }\n",
    "    return image_paths_per_label\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Returns a preprocessed image.\n",
    "\n",
    "    Parameters:\n",
    "        image: A RGB image with pixel values in range [0, 255].\n",
    "    Returns\n",
    "        image: The preprocessed image.\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.resize(image, (180, 180))\n",
    "    image = image / 255.\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\\train\\Picasso\\150.jpg --> FAILED\n",
      "dataset\\test\\Picasso\\1503.jpg --> FAILED\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels) = create_data_with_labels(\"dataset/train/\")\n",
    "(val_data, val_labels) = create_data_with_labels(\"dataset/validation\")\n",
    "(test_data, test_labels) = create_data_with_labels(\"dataset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2753, 180, 180, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ter controle, we zien dat de het resizen naar 180x180 gelukt is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60a9a335d522aefda6eaa043709c97f9746d66f97309f2f09eaf1fc365ea87e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
